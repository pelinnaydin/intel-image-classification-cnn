{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":269359,"sourceType":"datasetVersion","datasetId":111880}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Intel Image Classification – CNN Projesi\nBu proje kapsamında CNN tabanlı bir model ile 6 farklı görüntü sınıfını \n(Buildings, Forest, Glacier, Mountain, Sea, Street) sınıflandırmayı amaçlıyorum.\n","metadata":{}},{"cell_type":"code","source":"Adımlar\n1. Veri yükleme ve keşif \n2. Train/Validation/Test ayrımı\n3. Data Augmentation\n4. CNN modeli (Conv, Pooling, Dropout, Dense)\n5. Modelin eğitimi\n6. Değerlendirme (Accuracy/Loss grafikleri, CM, CR, Grad-CAM)\n7. Hiperparametre denemeleri\n8. Sonuçlar ve çıkarımlar\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T17:43:08.211386Z","iopub.status.idle":"2025-09-24T17:43:08.211618Z","shell.execute_reply.started":"2025-09-24T17:43:08.211517Z","shell.execute_reply":"2025-09-24T17:43:08.211526Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 2) Veri Önişleme\n\nBu bölümde:\n- Klasör yapısını doğruluyorum (train/test).\n- Train setten %20 validation çıkarıyorum.\n- Görselleri 224×224 boyutlandırıyorum.\n- Sınıf dağılımını ve örnek görselleri gösteriyorum (EDA).\n- Data augmentation katmanını hazırlıyorum (flip/rotation/zoom/contrast).\n- tf.data performans ayarlarını (cache/prefetch) yapıyorum.\n","metadata":{}},{"cell_type":"code","source":"import os, random, numpy as np, tensorflow as tf  # temel kütüphaneler\nimport matplotlib.pyplot as plt  # grafik çizimi\nfrom pathlib import Path  # path işlemleri \n\nSEED = 42   # tekrarlanabilirlik için seed\nrandom.seed(SEED); np.random.seed(SEED); tf.random.set_seed(SEED) # tüm kaynaklarda seed\n\n\nDATA_DIR = \"/kaggle/input/intel-image-classification\"    \ntrain_dir = f\"{DATA_DIR}/seg_train/seg_train\"   # train klasörü\ntest_dir  = f\"{DATA_DIR}/seg_test/seg_test\"   # test klasörü\n\nprint(\"GPU:\", tf.config.list_physical_devices('GPU'))   # GPU var mı?\nprint(\"Train path exists:\", os.path.exists(train_dir))   # train yolu kontrol\nprint(\"Test  path exists:\", os.path.exists(test_dir))     # test yolu kontrol\n\n\n!ls -lah /kaggle/input/intel-image-classification   # dataset kökü listele\n!ls -lah /kaggle/input/intel-image-classification/seg_train/seg_train | head -n 10  # train içeriği\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T13:09:42.420211Z","iopub.execute_input":"2025-09-25T13:09:42.420769Z","iopub.status.idle":"2025-09-25T13:09:43.815643Z","shell.execute_reply.started":"2025-09-25T13:09:42.420747Z","shell.execute_reply":"2025-09-25T13:09:43.814619Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.preprocessing import image_dataset_from_directory # klasörden tf.data dataset\n\nIMG_SIZE = (224, 224) #Tüm görselleri modele girmeden önce 224×224’e yeniden boyutlandırılır.\nBATCH = 32  # batch boyutu- her adımda 32 görüntü için\nAUTOTUNE = tf.data.AUTOTUNE \n\n# Train içinden %20 validation ayırıyoruz\ntrain_ds = image_dataset_from_directory(\n    train_dir,\n    validation_split=0.20, subset=\"training\", seed=SEED,\n    image_size=IMG_SIZE, batch_size=BATCH\n)\n# aynı split/seed ile validation dataset\nval_ds = image_dataset_from_directory(\n    train_dir,\n    validation_split=0.20, subset=\"validation\", seed=SEED,\n    image_size=IMG_SIZE, batch_size=BATCH\n)\n\n# Test set (ayrı klasörden)\ntest_ds = image_dataset_from_directory(\n    test_dir,\n    image_size=IMG_SIZE, batch_size=BATCH, shuffle=False\n)\n\nclass_names = train_ds.class_names  # sınıf adları \nnum_classes = len(class_names)   # sınıf sayısı\nclass_names, num_classes    # hızlı kontrol (Jupyter çıktısı)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T13:10:00.340518Z","iopub.execute_input":"2025-09-25T13:10:00.340771Z","iopub.status.idle":"2025-09-25T13:10:01.559680Z","shell.execute_reply.started":"2025-09-25T13:10:00.340753Z","shell.execute_reply":"2025-09-25T13:10:01.559087Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Eğitim sırasında okuma performansı için:\ntrain_ds = train_ds.cache().shuffle(1000).prefetch(AUTOTUNE)\nval_ds   = val_ds.cache().prefetch(AUTOTUNE)\ntest_ds  = test_ds.cache().prefetch(AUTOTUNE)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T13:10:01.560309Z","iopub.execute_input":"2025-09-25T13:10:01.560517Z","iopub.status.idle":"2025-09-25T13:10:01.578425Z","shell.execute_reply.started":"2025-09-25T13:10:01.560501Z","shell.execute_reply":"2025-09-25T13:10:01.577686Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Klasörlerden dosya sayısı \ncounts = {}\n# eğitim klasöründeki sınıf klasörleri alfabetik taranır\nfor cls in sorted(os.listdir(train_dir)):\n    p = Path(train_dir) / cls   # sınıf klasörünün yolu\n    if p.is_dir(): # yalnızca klasör olanlar dikkate alınır\n        counts[cls] = len(list(p.glob(\"*\")))  # üst seviye dosya sayısı hesaplanır\ncounts\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T13:10:06.121154Z","iopub.execute_input":"2025-09-25T13:10:06.121768Z","iopub.status.idle":"2025-09-25T13:10:06.152304Z","shell.execute_reply.started":"2025-09-25T13:10:06.121744Z","shell.execute_reply":"2025-09-25T13:10:06.151603Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt # görselleştirme arayüzü\n\nlabels = list(counts.keys())   # sınıf adları (x-ekseni)\nvalues = [counts[k] for k in labels]     # sınıf başına örnek sayısı (y-ekseni)\n \nplt.figure(figsize=(6,4))  # tuval boyutu\nplt.bar(labels, values)    # çubuk grafik\nplt.title(\"Train sınıf dağılımı\")  # başlık\nplt.xticks(rotation=45)   # x etiketlerini döndür\nplt.ylabel(\"Görsel sayısı\")    # y ekseni açıklaması\nplt.show()     # grafik görüntülenir\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T13:10:08.459917Z","iopub.execute_input":"2025-09-25T13:10:08.460206Z","iopub.status.idle":"2025-09-25T13:10:08.742333Z","shell.execute_reply.started":"2025-09-25T13:10:08.460185Z","shell.execute_reply":"2025-09-25T13:10:08.741619Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(8,8))\nfor images, labels in train_ds.take(1):  # tek bir batch alınıyor\n    for i in range(12):  # ilk 12 örnek görselleştiriliyor\n        ax = plt.subplot(3,4,i+1)\n        plt.imshow(images[i].numpy().astype(\"uint8\"))\n        plt.title(class_names[labels[i]])\n        plt.axis(\"off\")  # eksenleri gizlemek için \nplt.tight_layout(); plt.show()  # Kenar boşlukları otomatik ayarlanır ve grafik gösterilir.\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T13:10:10.869114Z","iopub.execute_input":"2025-09-25T13:10:10.869400Z","iopub.status.idle":"2025-09-25T13:10:29.374590Z","shell.execute_reply.started":"2025-09-25T13:10:10.869362Z","shell.execute_reply":"2025-09-25T13:10:29.373529Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"try:\n    train_ds     # train_ds tanımlı mı kontrolü\nexcept NameError: #tanımlı değilse aşağıdaki “yeniden kurulum” bloğu çalıştırılır.\n    from tensorflow.keras.preprocessing import image_dataset_from_directory #Klasör yapısından tf.data.Dataset üretmek için gerekli yardımcı fonksiyon içe aktarılır.\n    SEED = 42; IMG_SIZE=(224,224); BATCH=32 #Tekrarlanabilirlik, hedef giriş boyutu ve batch büyüklüğü sabitleri tanımlanır.\n    DATA_DIR=\"/kaggle/input/intel-image-classification\"\n    train_dir=f\"{DATA_DIR}/seg_train/seg_train\"   # Train klasörü - Eğitim verisinin bulunduğu klasör yolu oluşturulur.\n    train_ds = image_dataset_from_directory(\n        train_dir, validation_split=0.20, subset=\"training\", seed=SEED,\n        image_size=IMG_SIZE, batch_size=BATCH\n    )\n    class_names = train_ds.class_names  # sınıf adları \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T13:10:29.375692Z","iopub.execute_input":"2025-09-25T13:10:29.375906Z","iopub.status.idle":"2025-09-25T13:10:29.380564Z","shell.execute_reply.started":"2025-09-25T13:10:29.375891Z","shell.execute_reply":"2025-09-25T13:10:29.379524Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf #TensorFlow çekirdeği içe aktarılır.\nfrom tensorflow.keras import Sequential #Birden çok katmanı sıralı biçimde tanımlamak için Sequential sınıfı alınır.\nfrom tensorflow.keras.layers import RandomFlip, RandomRotation, RandomZoom, RandomContrast #Eğitim sırasında anlık veri çoğaltma yapan ön-işleme katmanları içe aktarılır.\n\ndata_augmentation = Sequential([\n    RandomFlip(\"horizontal\"),   # yatay çevirme\n    RandomRotation(0.15),       # küçük açısal döndürme (faktör=0.15)\n    RandomZoom(0.10),       \n    RandomContrast(0.10),       \n], name=\"augmentation\")\n\ndata_augmentation\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T13:10:29.381333Z","iopub.execute_input":"2025-09-25T13:10:29.381690Z","iopub.status.idle":"2025-09-25T13:10:29.414078Z","shell.execute_reply.started":"2025-09-25T13:10:29.381674Z","shell.execute_reply":"2025-09-25T13:10:29.413453Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# train'den tek batch al, ilk görseli 1'lik batch olarak seç\nfor images, labels in train_ds.take(1):\n    sample = images[0:1]\n    break\n\nimport matplotlib.pyplot as plt\nplt.figure(figsize=(10,3))\n\n# Orijinal\nplt.subplot(1,3,1); plt.imshow(sample[0].numpy().astype(\"uint8\")); plt.title(\"Orijinal\"); plt.axis(\"off\")\n\n# Aug1\naug1 = data_augmentation(sample, training=True)\nplt.subplot(1,3,2); plt.imshow(aug1[0].numpy().astype(\"uint8\")); plt.title(\"Aug1\"); plt.axis(\"off\")\n\n# Aug2\naug2 = data_augmentation(sample, training=True)\nplt.subplot(1,3,3); plt.imshow(aug2[0].numpy().astype(\"uint8\")); plt.title(\"Aug2\"); plt.axis(\"off\")\n\nplt.tight_layout(); plt.show()  # düzenle ve göster\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T13:11:08.088008Z","iopub.execute_input":"2025-09-25T13:11:08.088653Z","iopub.status.idle":"2025-09-25T13:11:10.652744Z","shell.execute_reply.started":"2025-09-25T13:11:08.088628Z","shell.execute_reply":"2025-09-25T13:11:10.652065Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"AUTOTUNE = tf.data.AUTOTUNE  # tf.data için otomatik ön getirme/işleme ayarı\n\ntrain_ds = train_ds.cache().shuffle(1000).prefetch(AUTOTUNE)\n\n# Eğer daha önce val_ds ve test_ds oluşturdıysan bunları da hızlandır:\ntry:\n    val_ds = val_ds.cache().prefetch(AUTOTUNE)\n    test_ds = test_ds.cache().prefetch(AUTOTUNE)\nexcept NameError:\n    pass  # henüz tanımlı değilse  geç\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T13:11:13.488201Z","iopub.execute_input":"2025-09-25T13:11:13.488502Z","iopub.status.idle":"2025-09-25T13:11:13.503523Z","shell.execute_reply.started":"2025-09-25T13:11:13.488481Z","shell.execute_reply":"2025-09-25T13:11:13.502945Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# importlar\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers, regularizers\n\n# sınıf sayısı \nclass_names = class_names if 'class_names' in globals() else train_ds.class_names\nnum_classes = len(class_names)\n\ntry:\n    data_augmentation\nexcept NameError:\n    from tensorflow.keras import Sequential\n    from tensorflow.keras.layers import RandomFlip, RandomRotation, RandomZoom, RandomContrast\n    data_augmentation = Sequential([\n        RandomFlip(\"horizontal\"),\n        RandomRotation(0.15),\n        RandomZoom(0.10),\n        RandomContrast(0.10),\n    ], name=\"augmentation\")\n\ndef build_baseline(input_shape=(224,224,3), num_classes=6, l2=1e-4, dropout=0.3):\n    inputs = keras.Input(shape=input_shape)\n\n    x = data_augmentation(inputs)         \n    x = layers.Rescaling(1./255)(x)          # [0,1] ölçek\n\n    # conv blokları\n    x = layers.Conv2D(32, 3, padding=\"same\", activation=\"relu\",\n                      kernel_regularizer=regularizers.l2(l2))(x)\n    x = layers.MaxPooling2D()(x)\n\n    x = layers.Conv2D(64, 3, padding=\"same\", activation=\"relu\",\n                      kernel_regularizer=regularizers.l2(l2))(x)\n    x = layers.MaxPooling2D()(x)\n\n    x = layers.Conv2D(128, 3, padding=\"same\", activation=\"relu\",\n                      kernel_regularizer=regularizers.l2(l2))(x)\n    x = layers.MaxPooling2D()(x)\n\n    x = layers.Dropout(dropout)(x)           # ← katmanı tensora uygula\n    x = layers.Flatten()(x)                  # vektörleştir\n    x = layers.Dense(128, activation=\"relu\")(x)\n    x = layers.Dropout(dropout)(x)           # ← yine tensora uygula\n    outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n\n    return keras.Model(inputs, outputs, name=\"cnn_baseline\")\n\nmodel = build_baseline(num_classes=num_classes)\nmodel.summary()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T13:34:14.356529Z","iopub.execute_input":"2025-09-25T13:34:14.357123Z","iopub.status.idle":"2025-09-25T13:34:14.434882Z","shell.execute_reply.started":"2025-09-25T13:34:14.357100Z","shell.execute_reply":"2025-09-25T13:34:14.434140Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# derle (integer label → sparse loss)\nmodel.compile(\n    optimizer=keras.optimizers.Adam(1e-3),  \n    loss=\"sparse_categorical_crossentropy\",\n    metrics=[\"accuracy\"]\n)\n\n# callback'ler\nckpt   = keras.callbacks.ModelCheckpoint(\"best_baseline.keras\", monitor=\"val_accuracy\",\n                                         save_best_only=True, mode=\"max\")   # en iyiyi kaydet\nearly  = keras.callbacks.EarlyStopping(monitor=\"val_accuracy\",\n                                       patience=5, restore_best_weights=True)  # erken dur\nreduce = keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\",\n                                           factor=0.5, patience=2, verbose=1)  # lr düşür\n\nEPOCHS = 20  # istersen 15-30 arası dene\nhistory = model.fit(\n    train_ds,\n    validation_data=val_ds,\n    epochs=EPOCHS,\n    callbacks=[ckpt, early, reduce],\n    verbose=1\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T13:37:44.751167Z","iopub.execute_input":"2025-09-25T13:37:44.751455Z","iopub.status.idle":"2025-09-25T13:48:31.737531Z","shell.execute_reply.started":"2025-09-25T13:37:44.751436Z","shell.execute_reply":"2025-09-25T13:48:31.736823Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# eğitim/val eğrilerini çiz\nimport matplotlib.pyplot as plt\n\ndef plot_history(h, title=\"Baseline CNN\"):\n    acc = h.history.get(\"accuracy\", [])\n    val_acc = h.history.get(\"val_accuracy\", [])\n    loss = h.history.get(\"loss\", [])\n    val_loss = h.history.get(\"val_loss\", [])\n\n    plt.figure()\n    plt.plot(acc, label=\"train_acc\"); plt.plot(val_acc, label=\"val_acc\")\n    plt.title(f\"{title} - Accuracy\"); plt.xlabel(\"epoch\"); plt.legend()\n\n    plt.figure()\n    plt.plot(loss, label=\"train_loss\"); plt.plot(val_loss, label=\"val_loss\")\n    plt.title(f\"{title} - Loss\"); plt.xlabel(\"epoch\"); plt.legend()\n\nplot_history(history)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T13:51:17.329678Z","iopub.execute_input":"2025-09-25T13:51:17.330580Z","iopub.status.idle":"2025-09-25T13:51:17.724298Z","shell.execute_reply.started":"2025-09-25T13:51:17.330556Z","shell.execute_reply":"2025-09-25T13:51:17.723548Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nimport numpy as np\nfrom sklearn.metrics import confusion_matrix, classification_report\n\n# tahminleri topla\ny_true, y_pred = [], []\nfor X, y in val_ds:\n    p = model.predict(X, verbose=0)\n    y_true.extend(y.numpy())\n    y_pred.extend(np.argmax(p, axis=1))\n\ny_true = np.array(y_true); y_pred = np.array(y_pred)\n\n# rapor + matris\nprint(classification_report(y_true, y_pred, target_names=class_names))\ncm = confusion_matrix(y_true, y_pred)\n\n# görselleştir \ntry:\n    import seaborn as sns\n    import matplotlib.pyplot as plt\n    plt.figure(figsize=(6,5))\n    sns.heatmap(cm, annot=True, fmt=\"d\",\n                xticklabels=class_names, yticklabels=class_names)\n    plt.xlabel(\"Predicted\"); plt.ylabel(\"True\"); plt.title(\"Confusion Matrix\")\n    plt.show()\nexcept Exception:\n    plt.figure(figsize=(6,5))\n    plt.imshow(cm, cmap=\"Blues\"); plt.colorbar()\n    plt.xticks(range(len(class_names)), class_names, rotation=45)\n    plt.yticks(range(len(class_names)), class_names)\n    plt.xlabel(\"Predicted\"); plt.ylabel(\"True\"); plt.title(\"Confusion Matrix\")\n    for i in range(cm.shape[0]):\n        for j in range(cm.shape[1]):\n            plt.text(j, i, cm[i, j], ha=\"center\", va=\"center\")\n    plt.tight_layout(); plt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T13:53:08.658337Z","iopub.execute_input":"2025-09-25T13:53:08.658901Z","iopub.status.idle":"2025-09-25T13:53:17.540458Z","shell.execute_reply.started":"2025-09-25T13:53:08.658877Z","shell.execute_reply":"2025-09-25T13:53:17.539724Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nimport tensorflow as tf\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef get_last_conv_name(m):\n    # sondan ilk Conv2D'yi bul\n    for layer in reversed(m.layers):\n        if isinstance(layer, tf.keras.layers.Conv2D):\n            return layer.name\n    raise ValueError(\"Conv2D katmanı bulunamadı.\")\n\ndef grad_cam_heatmap(m, img_tensor, last_conv_layer_name=None, pred_index=None):\n    # img_tensor: (1, H, W, 3) float32\n    if last_conv_layer_name is None:\n        last_conv_layer_name = get_last_conv_name(m)\n\n    grad_model = tf.keras.Model([m.inputs],\n                                [m.get_layer(last_conv_layer_name).output, m.output])\n\n    with tf.GradientTape() as tape:\n        conv_out, preds = grad_model(img_tensor, training=False)\n        if pred_index is None:\n            pred_index = tf.argmax(preds[0])\n        loss = preds[:, pred_index]\n\n    grads = tape.gradient(loss, conv_out)            # dloss/dconv\n    pooled = tf.reduce_mean(grads, axis=(0,1,2))     # kanal ağırlıkları\n    conv_out = conv_out[0]\n    heatmap = tf.reduce_sum(pooled * conv_out, axis=-1)\n\n    # normalize [0,1]\n    heatmap = tf.maximum(heatmap, 0)\n    denom = tf.reduce_max(heatmap) + 1e-8\n    heatmap = heatmap / denom\n    return heatmap.numpy()\n\n# val setinden bir örnek al ve Grad-CAM göster\nfor images, labels in val_ds.take(1):\n    img = images[0:1]                 # (1,224,224,3) uint8\n    lbl = labels[0].numpy()\n    break\n\n# model girişi gibi ölçekle: (aug içinde rescaling var ama görselleştirme için img/255 kullanacağız)\nimg_float = tf.cast(img, tf.float32) / 255.0\nhm = grad_cam_heatmap(model, img_float)             # 2D heatmap\n\n# görselleştir: orijinal + overlay\nplt.figure(figsize=(8,4))\nplt.subplot(1,2,1)\nplt.imshow(img[0].numpy().astype(\"uint8\")); plt.title(f\"True: {class_names[lbl]}\"); plt.axis(\"off\")\n\nplt.subplot(1,2,2)\nplt.imshow(img[0].numpy().astype(\"uint8\"));        # arka plan\nplt.imshow(tf.image.resize(hm[...,None], (img.shape[1], img.shape[2]))[...,0],\n           cmap=\"jet\", alpha=0.4)                   \nplt.title(\"Grad-CAM\"); plt.axis(\"off\")\nplt.tight_layout(); plt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T13:53:33.212850Z","iopub.execute_input":"2025-09-25T13:53:33.213673Z","iopub.status.idle":"2025-09-25T13:53:34.115111Z","shell.execute_reply.started":"2025-09-25T13:53:33.213652Z","shell.execute_reply":"2025-09-25T13:53:34.114437Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_loss, test_acc = model.evaluate(test_ds, verbose=0)\nprint(f\"TEST acc: {test_acc:.3f} | loss: {test_loss:.3f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T13:53:52.898471Z","iopub.execute_input":"2025-09-25T13:53:52.898913Z","iopub.status.idle":"2025-09-25T13:53:57.517909Z","shell.execute_reply.started":"2025-09-25T13:53:52.898893Z","shell.execute_reply":"2025-09-25T13:53:57.517307Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# derlemek için\nmodel.compile(\n    optimizer=keras.optimizers.Adam(1e-3),  \n    loss=\"sparse_categorical_crossentropy\",\n    metrics=[\"accuracy\"]\n)\n\n# callback'ler\nckpt   = keras.callbacks.ModelCheckpoint(\"best_baseline.keras\", monitor=\"val_accuracy\",\n                                         save_best_only=True, mode=\"max\")   # en iyiyi kaydet\nearly  = keras.callbacks.EarlyStopping(monitor=\"val_accuracy\",\n                                       patience=5, restore_best_weights=True)  \nreduce = keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\",\n                                           factor=0.5, patience=2, verbose=1)  # lr düşür\n\nEPOCHS = 20  # hızlı denemede 10-15 de olur\nhistory = model.fit(\n    train_ds,\n    validation_data=val_ds,\n    epochs=EPOCHS,\n    callbacks=[ckpt, early, reduce],\n    verbose=1\n)\n\n# hızlı skor (val + test)\nval_loss,  val_acc  = model.evaluate(val_ds,  verbose=0)\ntest_loss, test_acc = model.evaluate(test_ds, verbose=0)\nprint(f\"VAL  acc: {val_acc:.3f} | loss: {val_loss:.3f}\")\nprint(f\"TEST acc: {test_acc:.3f} | loss: {test_loss:.3f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T14:55:30.591488Z","iopub.execute_input":"2025-09-25T14:55:30.592128Z","iopub.status.idle":"2025-09-25T15:00:54.208534Z","shell.execute_reply.started":"2025-09-25T14:55:30.592105Z","shell.execute_reply":"2025-09-25T15:00:54.207587Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# MobileNetV2 tabanı (dondur + üstüne sınıflandırıcı ekle)\nbase = tf.keras.applications.MobileNetV2(\n    input_shape=(224,224,3), include_top=False, weights=\"imagenet\")\nbase.trainable = False  # önce dondur\n\ninputs = keras.Input(shape=(224,224,3))\nx = data_augmentation(inputs)\nx = tf.keras.applications.mobilenet_v2.preprocess_input(x)\nx = base(x, training=False)\nx = layers.GlobalAveragePooling2D()(x)\nx = layers.Dropout(0.3)(x)\noutputs = layers.Dense(num_classes, activation=\"softmax\")(x)\ntl_model = keras.Model(inputs, outputs, name=\"mobilenetv2_tl\")\n\ntl_model.compile(optimizer=keras.optimizers.Adam(1e-3),\n                 loss=\"sparse_categorical_crossentropy\",\n                 metrics=[\"accuracy\"])\ntl_hist = tl_model.fit(train_ds, validation_data=val_ds, epochs=5,\n                       callbacks=[early, reduce, ckpt])\n\nbase.trainable = True\nfor layer in base.layers[:-30]:\n    layer.trainable = False\n\ntl_model.compile(optimizer=keras.optimizers.Adam(1e-4),\n                 loss=\"sparse_categorical_crossentropy\",\n                 metrics=[\"accuracy\"])\ntl_fine = tl_model.fit(train_ds, validation_data=val_ds, epochs=5,\n                       callbacks=[early, reduce, ckpt])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T15:01:42.330266Z","iopub.execute_input":"2025-09-25T15:01:42.330812Z","iopub.status.idle":"2025-09-25T15:06:33.343817Z","shell.execute_reply.started":"2025-09-25T15:01:42.330790Z","shell.execute_reply":"2025-09-25T15:06:33.343244Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nFAST = False \n\n\n%matplotlib inline\ndef plot_history(h, title=\"Model\"):\n    if h is None or not hasattr(h, \"history\"):\n        print(\"history bulunamadı → önce model.fit(...)\")\n        return\n    import matplotlib.pyplot as plt\n    acc, val_acc = h.history.get(\"accuracy\", []), h.history.get(\"val_accuracy\", [])\n    loss, val_loss = h.history.get(\"loss\", []), h.history.get(\"val_loss\", [])\n    plt.figure(); plt.plot(acc,label=\"train_acc\"); plt.plot(val_acc,label=\"val_acc\"); plt.title(f\"{title}-Acc\"); plt.legend()\n    plt.figure(); plt.plot(loss,label=\"train_loss\"); plt.plot(val_loss,label=\"val_loss\"); plt.title(f\"{title}-Loss\"); plt.legend()\n\nplot_history(globals().get(\"history\", None), \"Baseline CNN\")\n\n\nimport numpy as np\nfrom sklearn.metrics import confusion_matrix, classification_report\nimport matplotlib.pyplot as plt\n\ntest_iter = test_ds.take(10) if FAST else test_ds  # hızlı/ tam\ny_true = np.concatenate([y.numpy() for _, y in test_iter], axis=0)\ny_pred = np.argmax(model.predict(test_iter, verbose=0), axis=1)\n\nprint(classification_report(y_true, y_pred, target_names=class_names))\n\ncm = confusion_matrix(y_true, y_pred)\ntry:\n    import seaborn as sns\n    plt.figure(figsize=(6,5))\n    sns.heatmap(cm, annot=True, fmt=\"d\", xticklabels=class_names, yticklabels=class_names)\n    plt.xlabel(\"Predicted\"); plt.ylabel(\"True\"); plt.title(\"Confusion Matrix\")\n    plt.tight_layout(); plt.show()\nexcept Exception:\n    plt.figure(figsize=(6,5)); plt.imshow(cm, cmap=\"Blues\"); plt.colorbar()\n    plt.xticks(range(len(class_names)), class_names, rotation=45)\n    plt.yticks(range(len(class_names)), class_names)\n    for i in range(cm.shape[0]):\n        for j in range(cm.shape[1]):\n            plt.text(j, i, cm[i, j], ha=\"center\", va=\"center\")\n    plt.title(\"Confusion Matrix\"); plt.tight_layout(); plt.show()\n\n\nimport tensorflow as tf\n\ndef get_last_conv_name(m):\n    for layer in reversed(m.layers):\n        if isinstance(layer, tf.keras.layers.Conv2D): return layer.name\n    raise ValueError(\"Conv2D bulunamadı.\")\n\ndef grad_cam_heatmap(m, img_tensor, last_conv_layer_name=None):\n    if last_conv_layer_name is None:\n        last_conv_layer_name = get_last_conv_name(m)\n    grad_model = tf.keras.Model([m.inputs],\n                                [m.get_layer(last_conv_layer_name).output, m.output])\n    with tf.GradientTape() as tape:\n        conv_out, preds = grad_model(img_tensor, training=False)\n        loss = preds[:, tf.argmax(preds[0])]\n    grads = tape.gradient(loss, conv_out)\n    weights = tf.reduce_mean(grads, axis=(0,1,2))\n    conv_out = conv_out[0]\n    heatmap = tf.reduce_sum(weights * conv_out, axis=-1)\n    heatmap = tf.maximum(heatmap, 0)\n    heatmap = heatmap / (tf.reduce_max(heatmap) + 1e-8)\n    return heatmap.numpy()\n\nn_show = 3 if FAST else 6\nfor imgs, labels in test_ds.take(1):  \n    for i in range(min(n_show, len(imgs))):\n        img  = imgs[i:i+1]\n        lbl  = labels[i].numpy()\n        imgf = tf.cast(img, tf.float32)   \n        hm   = grad_cam_heatmap(model, imgf)\n        hm   = tf.image.resize(hm[...,None], (img.shape[1], img.shape[2]))[...,0]\n\n        plt.figure(figsize=(8,4))\n        plt.subplot(1,2,1); plt.imshow(img[0].numpy().astype(\"uint8\"))\n        plt.title(f\"True: {class_names[lbl]}\"); plt.axis(\"off\")\n        plt.subplot(1,2,2); plt.imshow(img[0].numpy().astype(\"uint8\"))\n        plt.imshow(hm, cmap=\"jet\", alpha=0.4)\n        pred = class_names[int(tf.argmax(model(imgf, training=False), axis=1)[0])]\n        plt.title(f\"Grad-CAM (Pred: {pred})\"); plt.axis(\"off\")\n        plt.tight_layout(); plt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T16:49:34.174077Z","iopub.execute_input":"2025-09-25T16:49:34.174372Z","iopub.status.idle":"2025-09-25T16:49:38.805784Z","shell.execute_reply.started":"2025-09-25T16:49:34.174353Z","shell.execute_reply":"2025-09-25T16:49:38.805101Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Acc/Loss grafiğini kaydet\nplot_history(history, \"Baseline CNN\")\nimport matplotlib.pyplot as plt\nplt.savefig(\"acc_loss_baseline.png\", dpi=200, bbox_inches=\"tight\")\n\n# Test raporu + CM’yi kaydet\nimport numpy as np\nfrom sklearn.metrics import confusion_matrix, classification_report\ny_true = np.concatenate([y.numpy() for _, y in test_ds], axis=0)\ny_pred = np.argmax(model.predict(test_ds, verbose=0), axis=1)\nwith open(\"classification_report_test.txt\",\"w\") as f:\n    f.write(classification_report(y_true, y_pred, target_names=class_names))\nimport seaborn as sns\ncm = confusion_matrix(y_true, y_pred)\nsns.heatmap(cm, annot=True, fmt=\"d\",\n            xticklabels=class_names, yticklabels=class_names)\nplt.tight_layout(); plt.savefig(\"cm_test.png\", dpi=200); plt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T16:49:59.965870Z","iopub.execute_input":"2025-09-25T16:49:59.966144Z","iopub.status.idle":"2025-09-25T16:50:02.154295Z","shell.execute_reply.started":"2025-09-25T16:49:59.966124Z","shell.execute_reply":"2025-09-25T16:50:02.153534Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# parametrik CNN (blok sayısı, filtre, kernel, dropout, dense, l2)\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers, regularizers\n\ndef build_cnn(input_shape=(224,224,3), num_classes=6,\n              num_blocks=3, base_filters=32, kernel_size=3,\n              dense_units=128, dropout=0.3, l2=1e-4):\n    inputs = keras.Input(shape=input_shape)\n    x = data_augmentation(inputs)        # aug\n    x = layers.Rescaling(1./255)(x)      # [0,1]\n\n    # conv blokları\n    f = base_filters\n    for b in range(num_blocks):\n        x = layers.Conv2D(f, kernel_size, padding=\"same\", activation=\"relu\",\n                          kernel_regularizer=regularizers.l2(l2))(x)\n        x = layers.MaxPooling2D()(x)\n        f *= 2  # her blokta kanal sayısını artırır\n\n    x = layers.Dropout(dropout)(x)\n    x = layers.Flatten()(x)\n    x = layers.Dense(dense_units, activation=\"relu\")(x)\n    x = layers.Dropout(dropout)(x)\n    outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n    return keras.Model(inputs, outputs)\n\ndef make_optimizer(name=\"adam\", lr=1e-3):\n    name = name.lower()\n    if name == \"adam\":\n        return keras.optimizers.Adam(lr)\n    if name == \"rmsprop\":\n        return keras.optimizers.RMSprop(lr)\n    # sgd (momentumlu)\n    return keras.optimizers.SGD(lr, momentum=0.9, nesterov=True)\n\ndef compile_model(model, opt_name=\"adam\", lr=1e-3):\n    opt = make_optimizer(opt_name, lr)\n    model.compile(optimizer=opt,\n                  loss=\"sparse_categorical_crossentropy\",\n                  metrics=[\"accuracy\"])\n    return model\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T16:53:42.924146Z","iopub.execute_input":"2025-09-25T16:53:42.924633Z","iopub.status.idle":"2025-09-25T16:53:42.932254Z","shell.execute_reply.started":"2025-09-25T16:53:42.924611Z","shell.execute_reply":"2025-09-25T16:53:42.931441Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"AUTOTUNE = tf.data.AUTOTUNE\n\ndef rebatched(ds, bs):\n   \n    return ds.unbatch().batch(bs).prefetch(AUTOTUNE)\n\ndef train_eval(cfg, fast=True):\n    \"\"\"\n    cfg: dict → {num_blocks, base_filters, kernel_size, dense_units, dropout, l2, lr, opt, batch}\n    fast=True → hızlı deneme (train/val'in küçük dilimi, az epoch)\n    \"\"\"\n    # batch ayarı\n    bs = cfg.get(\"batch\", 32)\n    tr = rebatched(train_ds, bs)\n    va = rebatched(val_ds,   bs)\n\n  \n    if fast:\n        tr = tr.take(120)   \n        va = va.take(40)\n        epochs = 8\n    else:\n        epochs = 20\n\n\n    m = build_cnn(num_classes=len(class_names),\n                  num_blocks=cfg[\"num_blocks\"],\n                  base_filters=cfg[\"base_filters\"],\n                  kernel_size=cfg[\"kernel_size\"],\n                  dense_units=cfg[\"dense_units\"],\n                  dropout=cfg[\"dropout\"],\n                  l2=cfg[\"l2\"])\n    m = compile_model(m, opt_name=cfg[\"opt\"], lr=cfg[\"lr\"])\n\n    # callback'ler\n    cbs = [\n        keras.callbacks.EarlyStopping(monitor=\"val_accuracy\", patience=3,\n                                      restore_best_weights=True),\n        keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5,\n                                          patience=2, verbose=0),\n    ]\n\n    h = m.fit(tr, validation_data=va, epochs=epochs, verbose=0, callbacks=cbs)\n   \n    best_val = max(h.history.get(\"val_accuracy\", [0.0]))\n    return best_val, h, m\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T16:53:53.744768Z","iopub.execute_input":"2025-09-25T16:53:53.745311Z","iopub.status.idle":"2025-09-25T16:53:53.752152Z","shell.execute_reply.started":"2025-09-25T16:53:53.745289Z","shell.execute_reply":"2025-09-25T16:53:53.751324Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import itertools, random\n\n\nspace = {\n    \"num_blocks\":   [2, 3],         # katman/derinlik\n    \"base_filters\": [32, 48],       # başlangıç kanal sayısı\n    \"kernel_size\":  [3, 5],         # kernel boyutu\n    \"dense_units\":  [128, 256],     # FC boyutu\n    \"dropout\":      [0.3, 0.4],     # dropout\n    \"l2\":           [1e-4, 5e-4],   # L2 ceza\n    \"lr\":           [1e-3, 5e-4],   # öğrenme hızı\n    \"opt\":          [\"adam\", \"sgd\"],# optimizer\n    \"batch\":        [32, 64],       # batch size\n}\n\n\nall_cfgs = [\n    dict(zip(space.keys(), vals))\n    for vals in itertools.product(*space.values())\n]\nrandom.seed(42)\nSAMPLE = 16   \ntrial_cfgs = random.sample(all_cfgs, k=min(SAMPLE, len(all_cfgs)))\nlen(trial_cfgs)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T16:55:58.037137Z","iopub.execute_input":"2025-09-25T16:55:58.037461Z","iopub.status.idle":"2025-09-25T16:55:58.045329Z","shell.execute_reply.started":"2025-09-25T16:55:58.037437Z","shell.execute_reply":"2025-09-25T16:55:58.044756Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.preprocessing import image_dataset_from_directory\nimport os\n\nSEED = 42\nDATA_DIR = \"/kaggle/input/intel-image-classification\"\ntrain_dir = f\"{DATA_DIR}/seg_train/seg_train\"\ntest_dir  = f\"{DATA_DIR}/seg_test/seg_test\"\n\nIMG_SIZE = (224, 224)\nBATCH = 32\nAUTOTUNE = tf.data.AUTOTUNE\n\n\ntrain_ds_raw = image_dataset_from_directory(\n    train_dir,\n    validation_split=0.20, subset=\"training\", seed=SEED,\n    image_size=IMG_SIZE, batch_size=BATCH\n)\nval_ds_raw = image_dataset_from_directory(\n    train_dir,\n    validation_split=0.20, subset=\"validation\", seed=SEED,\n    image_size=IMG_SIZE, batch_size=BATCH\n)\ntest_ds_raw = image_dataset_from_directory(\n    test_dir,\n    image_size=IMG_SIZE, batch_size=BATCH, shuffle=False\n)\n\n\nclass_names = train_ds_raw.class_names\nnum_classes = len(class_names)\nprint(\"classes:\", class_names)\n\ntrain_ds = train_ds_raw.cache().prefetch(AUTOTUNE)\nval_ds   = val_ds_raw.cache().prefetch(AUTOTUNE)\ntest_ds  = test_ds_raw.cache().prefetch(AUTOTUNE)\n\n\nif 'data_augmentation' not in globals():\n    from tensorflow.keras import Sequential\n    from tensorflow.keras.layers import RandomFlip, RandomRotation, RandomZoom, RandomContrast\n    data_augmentation = Sequential([\n        RandomFlip(\"horizontal\"),\n        RandomRotation(0.15),\n        RandomZoom(0.10),\n        RandomContrast(0.10),\n    ], name=\"augmentation\")\n\nprint(\"train/val/test hazır.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T11:08:29.207046Z","iopub.execute_input":"2025-09-26T11:08:29.207866Z","iopub.status.idle":"2025-09-26T11:08:32.775351Z","shell.execute_reply.started":"2025-09-26T11:08:29.207839Z","shell.execute_reply":"2025-09-26T11:08:32.774800Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# küçük log temizliği + GPU güvenliği\nimport os, gc, tensorflow as tf\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\ntry:\n    tf.get_logger().setLevel(\"ERROR\")\n    tf.config.optimizer.set_experimental_options({'layout_optimizer': False})\n    for g in tf.config.list_physical_devices('GPU'):\n        try: tf.config.experimental.set_memory_growth(g, True)\n        except: pass\nexcept: pass\n\ndef _clear():\n\n    tf.keras.backend.clear_session(); gc.collect()\n\nAUTOTUNE = tf.data.AUTOTUNE\ndef rebatched(ds, bs):\n    # batch boyutunu değiştirir\n    return ds.unbatch().batch(bs).prefetch(AUTOTUNE)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T11:00:01.908118Z","iopub.execute_input":"2025-09-26T11:00:01.908805Z","iopub.status.idle":"2025-09-26T11:00:23.720941Z","shell.execute_reply.started":"2025-09-26T11:00:01.908778Z","shell.execute_reply":"2025-09-26T11:00:23.720383Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# parametrik CNN kurucu\nfrom tensorflow import keras\nfrom tensorflow.keras import layers, regularizers\n\ndef build_cnn(input_shape=(224,224,3), num_classes=6,\n              num_blocks=3, base_filters=32, kernel_size=3,\n              dense_units=128, dropout=0.3, l2=1e-4):\n    inputs = keras.Input(shape=input_shape)\n    x = data_augmentation(inputs)           # aug\n    x = layers.Rescaling(1./255)(x)         # [0,1]\n\n    f = base_filters\n    for _ in range(num_blocks):             # derinlik = blok sayısı\n        x = layers.Conv2D(f, kernel_size, padding=\"same\", activation=\"relu\",\n                          kernel_regularizer=regularizers.l2(l2))(x)\n        x = layers.MaxPooling2D()(x)\n        f *= 2                               # kanal sayısını artırır\n\n    x = layers.Dropout(dropout)(x)          # overfit freni\n    x = layers.Flatten()(x)\n    x = layers.Dense(dense_units, activation=\"relu\")(x)\n    x = layers.Dropout(dropout)(x)\n    outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n    return keras.Model(inputs, outputs)\n\ndef compile_model(model, opt_name=\"adam\", lr=1e-3):\n    opt_name = opt_name.lower()\n    if opt_name == \"adam\":\n        opt = keras.optimizers.Adam(lr)\n    elif opt_name == \"rmsprop\":\n        opt = keras.optimizers.RMSprop(lr)\n    else:\n        opt = keras.optimizers.SGD(lr, momentum=0.9, nesterov=True)\n    model.compile(optimizer=opt,\n                  loss=\"sparse_categorical_crossentropy\",\n                  metrics=[\"accuracy\"])\n    return model\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T11:00:54.144217Z","iopub.execute_input":"2025-09-26T11:00:54.144458Z","iopub.status.idle":"2025-09-26T11:00:54.151783Z","shell.execute_reply.started":"2025-09-26T11:00:54.144441Z","shell.execute_reply":"2025-09-26T11:00:54.151070Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\ndef train_eval_quick(cfg):\n    _clear()\n\n    \n    bs = min(cfg.get(\"batch\", 32), 32)\n\n  \n    steps_tr, steps_va, epochs = 40, 12, 3\n    tr = rebatched(train_ds, bs).take(steps_tr).repeat()\n    va = rebatched(val_ds,   bs).take(steps_va).repeat()\n\n    try:\n        m = build_cnn(num_classes=len(class_names),\n                      num_blocks=cfg[\"num_blocks\"],\n                      base_filters=cfg[\"base_filters\"],\n                      kernel_size=cfg[\"kernel_size\"],\n                      dense_units=cfg[\"dense_units\"],\n                      dropout=cfg[\"dropout\"],\n                      l2=cfg[\"l2\"])\n        m = compile_model(m, opt_name=cfg[\"opt\"], lr=cfg[\"lr\"])\n\n        h = m.fit(tr, validation_data=va, epochs=epochs,\n                  steps_per_epoch=steps_tr, validation_steps=steps_va,\n                  verbose=0,\n                  callbacks=[\n                      keras.callbacks.EarlyStopping(monitor=\"val_accuracy\", patience=2, restore_best_weights=True),\n                      keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=1, verbose=0),\n                  ])\n        best_val = max(h.history.get(\"val_accuracy\", [0.0]))\n        return best_val, h, m\n\n    except tf.errors.ResourceExhaustedError:\n      \n        _clear()\n        bs2 = max(8, bs // 2)\n        tr = rebatched(train_ds, bs2).take(steps_tr).repeat()\n        va = rebatched(val_ds,   bs2).take(steps_va).repeat()\n\n        bf2 = max(16, cfg[\"base_filters\"] // 2)\n        m = build_cnn(num_classes=len(class_names),\n                      num_blocks=cfg[\"num_blocks\"],\n                      base_filters=bf2,\n                      kernel_size=cfg[\"kernel_size\"],\n                      dense_units=cfg[\"dense_units\"],\n                      dropout=cfg[\"dropout\"],\n                      l2=cfg[\"l2\"])\n        m = compile_model(m, opt_name=cfg[\"opt\"], lr=cfg[\"lr\"])\n\n        h = m.fit(tr, validation_data=va, epochs=epochs,\n                  steps_per_epoch=steps_tr, validation_steps=steps_va,\n                  verbose=0,\n                  callbacks=[\n                      keras.callbacks.EarlyStopping(monitor=\"val_accuracy\", patience=2, restore_best_weights=True),\n                      keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=1, verbose=0),\n                  ])\n        best_val = max(h.history.get(\"val_accuracy\", [0.0]))\n        print(f\"[OOM çözüldü] batch->{bs2}, base_filters->{bf2}\")\n        return best_val, h, m\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T11:01:04.244604Z","iopub.execute_input":"2025-09-26T11:01:04.245321Z","iopub.status.idle":"2025-09-26T11:01:04.253557Z","shell.execute_reply.started":"2025-09-26T11:01:04.245297Z","shell.execute_reply":"2025-09-26T11:01:04.252909Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 6 mantıklı kombinasyon (katman/filtre/kernel/dropout/dense/l2/lr/opt/batch)\ntrial_cfgs = [\n  {'num_blocks':2,'base_filters':32,'kernel_size':3,'dense_units':128,'dropout':0.3,'l2':1e-4,'lr':1e-3,'opt':'adam','batch':32},\n  {'num_blocks':3,'base_filters':32,'kernel_size':3,'dense_units':128,'dropout':0.4,'l2':5e-4,'lr':1e-3,'opt':'adam','batch':32},\n  {'num_blocks':3,'base_filters':48,'kernel_size':3,'dense_units':256,'dropout':0.3,'l2':1e-4,'lr':5e-4,'opt':'adam','batch':32},\n  {'num_blocks':2,'base_filters':48,'kernel_size':5,'dense_units':256,'dropout':0.4,'l2':5e-4,'lr':1e-3,'opt':'sgd','batch':32},\n  {'num_blocks':3,'base_filters':32,'kernel_size':5,'dense_units':256,'dropout':0.3,'l2':5e-4,'lr':5e-4,'opt':'sgd','batch':32},\n  {'num_blocks':2,'base_filters':32,'kernel_size':3,'dense_units':128,'dropout':0.3,'l2':1e-4,'lr':5e-4,'opt':'adam','batch':32},\n]\nprint(\"trial_cfgs hazır:\", len(trial_cfgs), \"deneme\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T11:01:13.772787Z","iopub.execute_input":"2025-09-26T11:01:13.773363Z","iopub.status.idle":"2025-09-26T11:01:13.779292Z","shell.execute_reply.started":"2025-09-26T11:01:13.773338Z","shell.execute_reply":"2025-09-26T11:01:13.778462Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nresults = []\nbest = {\"val_acc\": -1, \"cfg\": None}\n\nfor i, cfg in enumerate(trial_cfgs, 1):\n    val_acc, _, _ = train_eval_quick(cfg)\n    results.append((val_acc, cfg))\n    if val_acc > best[\"val_acc\"]:\n        best = {\"val_acc\": val_acc, \"cfg\": cfg}\n    print(f\"[{i}/{len(trial_cfgs)}] val_acc={val_acc:.4f}  cfg={cfg}\")\n\n\nresults_sorted = sorted(results, key=lambda x: x[0], reverse=True)[:3]\nprint(\"\\nTOP-3 (val_acc):\")\nfor rank, (score, cfg) in enumerate(results_sorted, 1):\n    print(f\"{rank}. {score:.4f}  {cfg}\")\n\nprint(\"\\nSEÇİLEN (hızlı arama):\", best[\"cfg\"], \"val_acc=\", round(best[\"val_acc\"], 4))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T11:08:52.579706Z","iopub.execute_input":"2025-09-26T11:08:52.580204Z","iopub.status.idle":"2025-09-26T11:10:58.553252Z","shell.execute_reply.started":"2025-09-26T11:08:52.580181Z","shell.execute_reply":"2025-09-26T11:10:58.552459Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# seçilen konfigürasyon\nfinal_cfg = best[\"cfg\"]\nprint(\"Tam eğitim cfg:\", final_cfg)\n\n# dataset'i seçilen batch'e göre hazırla\nbs = final_cfg.get(\"batch\", 32)\ntr_full = rebatched(train_ds, bs)\nva_full = rebatched(val_ds,   bs)\n\n# model kur + derle\nfinal_model = build_cnn(num_classes=len(class_names),\n                        num_blocks=final_cfg[\"num_blocks\"],\n                        base_filters=final_cfg[\"base_filters\"],\n                        kernel_size=final_cfg[\"kernel_size\"],\n                        dense_units=final_cfg[\"dense_units\"],\n                        dropout=final_cfg[\"dropout\"],\n                        l2=final_cfg[\"l2\"])\nfinal_model = compile_model(final_model, opt_name=final_cfg[\"opt\"], lr=final_cfg[\"lr\"])\n\n# callback'ler\nfrom tensorflow import keras\nckpt_final = \"best_tuned.keras\"\ncbs_final = [\n    keras.callbacks.ModelCheckpoint(ckpt_final, monitor=\"val_accuracy\",\n                                    save_best_only=True, mode=\"max\"),\n    keras.callbacks.EarlyStopping(monitor=\"val_accuracy\", patience=5,\n                                  restore_best_weights=True),\n    keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5,\n                                      patience=2, verbose=1),\n]\n\nEPOCHS_FULL = 20  \nhistory_tuned = final_model.fit(\n    tr_full, validation_data=va_full,\n    epochs=EPOCHS_FULL, callbacks=cbs_final, verbose=1\n)\n\n\nval_loss,  val_acc  = final_model.evaluate(va_full,                verbose=0)\ntest_loss, test_acc = final_model.evaluate(rebatched(test_ds, bs), verbose=0)\nprint(f\"[TUNED] VAL  acc: {val_acc:.3f} | loss: {val_loss:.3f}\")\nprint(f\"[TUNED] TEST acc: {test_acc:.3f} | loss: {test_loss:.3f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T11:14:58.496901Z","iopub.execute_input":"2025-09-26T11:14:58.497517Z","iopub.status.idle":"2025-09-26T11:35:29.382769Z","shell.execute_reply.started":"2025-09-26T11:14:58.497489Z","shell.execute_reply":"2025-09-26T11:35:29.381999Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\ntry:\n    plot_history(history_tuned, \"Tuned\")\nexcept NameError:\n    import matplotlib.pyplot as plt\n    def plot_history(h, title=\"Model\"):\n        if h is None or not hasattr(h, \"history\"): return\n        acc, val_acc = h.history.get(\"accuracy\", []), h.history.get(\"val_accuracy\", [])\n        loss, val_loss = h.history.get(\"loss\", []), h.history.get(\"val_loss\", [])\n        plt.figure(); plt.plot(acc,label=\"train_acc\"); plt.plot(val_acc,label=\"val_acc\"); plt.title(f\"{title}-Acc\"); plt.legend()\n        plt.figure(); plt.plot(loss,label=\"train_loss\"); plt.plot(val_loss,label=\"val_loss\"); plt.title(f\"{title}-Loss\"); plt.legend()\n\n    plot_history(history_tuned, \"Tuned\")\n\n# rapor için PNG kaydı\nimport matplotlib.pyplot as plt\nplt.savefig(\"acc_loss_tuned.png\", dpi=200, bbox_inches=\"tight\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T11:41:02.695307Z","iopub.execute_input":"2025-09-26T11:41:02.695600Z","iopub.status.idle":"2025-09-26T11:41:03.594858Z","shell.execute_reply.started":"2025-09-26T11:41:02.695580Z","shell.execute_reply":"2025-09-26T11:41:03.594252Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np, matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix, classification_report\n\n# tüm testte tahmin\ny_true = np.concatenate([y.numpy() for _, y in test_ds], axis=0)\ny_pred = np.argmax(final_model.predict(test_ds, verbose=0), axis=1)\n\n# classification report\ncr = classification_report(y_true, y_pred, target_names=class_names)\nprint(cr)\nwith open(\"classification_report_test_tuned.txt\",\"w\") as f:\n    f.write(cr)\n\n# confusion matrix\ncm = confusion_matrix(y_true, y_pred)\ntry:\n    import seaborn as sns\n    plt.figure(figsize=(6,5))\n    sns.heatmap(cm, annot=True, fmt=\"d\",\n                xticklabels=class_names, yticklabels=class_names)\n    plt.xlabel(\"Predicted\"); plt.ylabel(\"True\"); plt.title(\"Confusion Matrix (Tuned, Test)\")\n    plt.tight_layout(); plt.savefig(\"cm_test_tuned.png\", dpi=200); plt.show()\nexcept Exception:\n    plt.figure(figsize=(6,5)); plt.imshow(cm, cmap=\"Blues\"); plt.colorbar()\n    plt.xticks(range(len(class_names)), class_names, rotation=45)\n    plt.yticks(range(len(class_names)), class_names)\n    for i in range(cm.shape[0]):\n        for j in range(cm.shape[1]):\n            plt.text(j, i, cm[i, j], ha=\"center\", va=\"center\")\n    plt.title(\"Confusion Matrix (Tuned, Test)\")\n    plt.tight_layout(); plt.savefig(\"cm_test_tuned.png\", dpi=200); plt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T11:41:17.165368Z","iopub.execute_input":"2025-09-26T11:41:17.165838Z","iopub.status.idle":"2025-09-26T11:41:21.341618Z","shell.execute_reply.started":"2025-09-26T11:41:17.165815Z","shell.execute_reply":"2025-09-26T11:41:21.340783Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf, matplotlib.pyplot as plt\n\n\ndef get_last_conv_name(m):\n    for layer in reversed(m.layers):\n        if isinstance(layer, tf.keras.layers.Conv2D):\n            return layer.name\n    raise ValueError(\"Conv2D bulunamadı.\")\n\ndef grad_cam_heatmap(m, img_tensor, last_conv_layer_name=None):\n    if last_conv_layer_name is None:\n        last_conv_layer_name = get_last_conv_name(m)\n    grad_model = tf.keras.Model([m.inputs],\n                                [m.get_layer(last_conv_layer_name).output, m.output])\n    with tf.GradientTape() as tape:\n        conv_out, preds = grad_model(img_tensor, training=False)\n        loss = preds[:, tf.argmax(preds[0])]\n    grads   = tape.gradient(loss, conv_out)\n    weights = tf.reduce_mean(grads, axis=(0,1,2))\n    conv_out = conv_out[0]\n    heatmap  = tf.reduce_sum(weights * conv_out, axis=-1)\n    heatmap  = tf.maximum(heatmap, 0)\n    heatmap  = heatmap / (tf.reduce_max(heatmap) + 1e-8)\n    return heatmap.numpy()\n\n\nn_show = 6\nfor imgs, labels in test_ds.take(1):\n    for i in range(min(n_show, len(imgs))):\n        img  = imgs[i:i+1]\n        lbl  = labels[i].numpy()\n        imgf = tf.cast(img, tf.float32)  \n        hm   = grad_cam_heatmap(final_model, imgf)\n        hm   = tf.image.resize(hm[...,None], (img.shape[1], img.shape[2]))[...,0]\n\n        plt.figure(figsize=(8,4))\n        plt.subplot(1,2,1); plt.imshow(img[0].numpy().astype(\"uint8\"))\n        plt.title(f\"True: {class_names[lbl]}\"); plt.axis(\"off\")\n        plt.subplot(1,2,2); plt.imshow(img[0].numpy().astype(\"uint8\"))\n        plt.imshow(hm, cmap=\"jet\", alpha=0.4)\n        pred = class_names[int(tf.argmax(final_model(imgf, training=False), axis=1)[0])]\n        plt.title(f\"Grad-CAM (Pred: {pred})\"); plt.axis(\"off\")\n        plt.tight_layout(); plt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T11:41:31.981784Z","iopub.execute_input":"2025-09-26T11:41:31.982352Z","iopub.status.idle":"2025-09-26T11:41:34.918505Z","shell.execute_reply.started":"2025-09-26T11:41:31.982326Z","shell.execute_reply":"2025-09-26T11:41:34.917905Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow import keras\nlog_dir = \"logs_fit\"\ntb_cb = keras.callbacks.TensorBoard(log_dir=log_dir)\n\n\n_ = final_model.fit(rebatched(train_ds, bs),\n                    validation_data=rebatched(val_ds, bs),\n                    epochs=2, callbacks=[tb_cb], verbose=1)\nprint(\"TensorBoard logları:\", log_dir)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T11:44:05.277634Z","iopub.execute_input":"2025-09-26T11:44:05.278172Z","iopub.status.idle":"2025-09-26T11:46:05.362691Z","shell.execute_reply.started":"2025-09-26T11:44:05.278149Z","shell.execute_reply":"2025-09-26T11:46:05.362143Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 5) Hiperparametre Optimizasyonu – Özet\n- Denenen parametreler: `num_blocks, base_filters, kernel_size, dropout, dense_units, l2, lr, optimizer, batch`.\n- Hızlı arama ile en iyi konfigürasyon seçildi: **{final_cfg}**.\n- Bu ayarla tam eğitim yapıldı: **VAL acc = …**, **TEST acc = …**.\n- Acc/Loss grafiği (`acc_loss_tuned.png`), Confusion Matrix (`cm_test_tuned.png`), Classification Report (`classification_report_test_tuned.txt`) üretildi.\n- Overfit/Underfit okuması: Eğitim/val eğrileri incelenerek gerekirse `dropout/L2/augment` ayarları revize edildi.\n","metadata":{}}]}